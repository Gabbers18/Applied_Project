---
title: "CRQA-Sample-Dataset"
output: pdf_document
date: "2025-05-05"
---

```{r setup, include=FALSE}
library(plyr)
library(crqa)
library(dplyr)
library(rMEA)
library(zoo)
library(tseriesChaos)
library(ggplot2)
library(purrr)
library(readr)
library(tidyr)
library(scales)
```

## Part 1: Motion Energy Analysis (MEA)

```{r MEA}
mea_normal <- readMEA("your_folder_path_to_MEA_files", 
sampRate = 25, s1Col = 2, s2Col = 1,
                     s1Name = "Participant2", s2Name = "Participant1", skip=1,
                     idOrder = c("id","session"), idSep="_")
```

# Part 2: Cross Recurrence Quantification Analysis (CRQA) 

## Step 1: DETERMINE PARAMETERS

```{r determine-parameters}
cross_theiler_window = 0
cross_rescale_type = 'mean'
radius = .1
```

## Step 2: Create a Random Sample

```{r random-sample}
set.seed(123)
dyads_to_sample <- sample(1:length(mea_normal), 5)
```

## Step 3: Create Functions for Parameter Calculation

### Preliminary function for Delay
```{r find-first-minimum}
find_first_minimum <- function(ami_values) {
  for (i in 2:(length(ami_values) - 1)) {
    if (ami_values[i] < ami_values[i - 1] && ami_values[i] < ami_values[i + 1]) {
      return(i)
    }
  }
  return(NULL)
}
```

### Preliminary function for Embedding Dimension
```{r find-elbow}
find_elbow <- function(fnn_values) {
  # Remove NA or Inf values from FNN values
  fnn_values <- fnn_values[is.finite(fnn_values)]
  
  # Calculate the difference between successive FNN values
  differences <- diff(fnn_values)
  
  # Loop through the differences to find the point of maximum curvature (the elbow)
  for (i in 2:(length(differences) - 2)) {
    if (!is.na(differences[i]) && !is.na(differences[i + 1]) &&
        differences[i] > differences[i + 1] && differences[i + 1] < differences[i + 2]) {
      return(i + 1)  # Return the embedding dimension at the elbow
    }
  }
  return(length(fnn_values))  # If no clear elbow is found, return the max embedding
}
```

## Step 4: Calculate Delay and Embedding Dimension Parameters

```{r determine-parameters}
# Initialize storage for delay and embedding dimensions
delays <- c()
embeddings <- c()

for (i in 1:length(dyads_to_sample)) {
  # Select the dyad
  dyad_data <- mea_normal[[dyads_to_sample[i]]][[1]]
  
  # Extract participant time series
  ts_participant1 <- dyad_data$Participant1
  ts_participant2 <- dyad_data$Participant2
  
  # Select the middle 60% of the time series
  ts_length <- length(ts_participant1)
  start_idx <- floor(0.2 * ts_length) + 1
  end_idx <- floor(0.8 * ts_length)
  ts_participant1s <- ts_participant1[start_idx:end_idx]
  ts_participant2s <- ts_participant2[start_idx:end_idx]
  
  # Determine delay using AMI
  cross_ami_p1 <- mutual(ts_participant1s, lag.max = 800)
  cross_ami_p2 <- mutual(ts_participant2s, lag.max = 800)
  
  chosen_delay_p1 <- find_first_minimum(cross_ami_p1)
  chosen_delay_p2 <- find_first_minimum(cross_ami_p2)
  cross_chosen_delay <- round(mean(c(chosen_delay_p1, chosen_delay_p2)))
  delays <- c(delays, cross_chosen_delay)
  
  # Determine embedding dimension using FNN and find the elbow
  cross_max_embedding <- 10
  cross_fnn_p1 <- false.nearest(ts_participant1s, m = cross_max_embedding, d = cross_chosen_delay, t = 0)
  cross_fnn_p2 <- false.nearest(ts_participant2s, m = cross_max_embedding, d = cross_chosen_delay, t = 0)
  
  elbow_p1 <- find_elbow(cross_fnn_p1)
  elbow_p2 <- find_elbow(cross_fnn_p2)
  cross_chosen_embedding <- round(mean(c(elbow_p1, elbow_p2)))
  embeddings <- c(embeddings, cross_chosen_embedding)
  
  plot(cross_fnn_p1, type = "b", main = paste("Dyad", dyads_to_sample[i], "- FNN P1"))
  plot(cross_fnn_p2, type = "b", main = paste("Dyad", dyads_to_sample[i], "- FNN P2"))
}
```
### Average Delay and Embedding Dimension Parameters
```{r sample-average}
average_delay <- round(mean(delays, na.rm = TRUE))
average_embedding <- round(mean(embeddings, na.rm = TRUE))

cat("Average Delay: ", average_delay, "\n")
cat("Average Embedding: ", average_embedding, "\n")
```

# CRQA - Full Run Through

## Step 5: Function for All Dyads

### Our Function
```{r function-all-dyads}
# Define the function to process each dyad and run CRQA
run_crqa_for_dyads <- function(df_list, cross_rescale_type, average_delay, average_embedding, cross_theiler_window) {
  
  # Create an empty list to store results
  crqa_results <- list()
  
  # Loop through each dyad in df_list
  for (dyad_name in names(df_list)) {
    
    # Check if the current dyad has both Participant 1 and Participant 2 time series
    if (grepl("Participant1", dyad_name)) {
      # Extract time series for Participant 1 and Participant 2
      ts_participant1 <- df_list[[dyad_name]]  # e.g., Dyad1000_Participant1_MEA
      ts_participant2 <- df_list[[gsub("Participant1", "Participant2", dyad_name)]]  # e.g., Dyad1000_Participant2_MEA

      # Convert lists to numeric vectors
      ts_participant1s <- unlist(ts_participant1)
      ts_participant1s <- as.numeric(ts_participant1s)
      ts_participant2s <- unlist(ts_participant2)
      ts_participant2s <- as.numeric(ts_participant2s)
      
      # Get middle 60 percent of the time series
      ts_participant1s <- get_middle_60_percent(ts_participant1s)
      ts_participant2s <- get_middle_60_percent(ts_participant2s)
      
      # Cross-rescaling based on the provided option
      if (cross_rescale_type == 'mean') {
        rescaled_p1 <- ts_participant1s / mean(ts_participant1s)
        rescaled_p2 <- ts_participant2s / mean(ts_participant2s)
      } else if (cross_rescale_type == 'max') {
        rescaled_p1 <- ts_participant1s / max(ts_participant1s)
        rescaled_p2 <- ts_participant2s / max(ts_participant2s)
      }
      
      # Perform the CRQA analysis
      crqa_analysis <- crqa(ts1 = rescaled_p1,
                            ts2 = rescaled_p2,
                            delay = average_delay,
                            embed = average_embedding,
                            r = radius,
                            normalize = 0,
                            rescale = 0,
                            mindiagline = 2,
                            minvertline = 2,
                            tw = cross_theiler_window,
                            whiteline = FALSE,
                            recpt = FALSE)
      
      # Extract the desired results from the CRQA analysis
      crqa_results[[dyad_name]] <- list(
        RR = crqa_analysis$RR,
        DET = crqa_analysis$DET,
        NRLINE = crqa_analysis$NRLINE,
        maxL = crqa_analysis$maxL,
        L = crqa_analysis$L,
        ENTR = crqa_analysis$ENTR,
        rENTR = crqa_analysis$rENTR,
        LAM = crqa_analysis$LAM,
        TT = crqa_analysis$TT
      )
    }
  }
  
  return(crqa_results)
}
```

## Step 6: Using the Function

``` {r run-all}
MEA_folder_path <- "your_folder_path"

txt_files <- list.files(path = MEA_folder_path, pattern = "\\.txt$", full.names = TRUE)

# Split the files into batches of 28
batch_size <- 28
batches <- split(txt_files, ceiling(seq_along(txt_files) / batch_size))

# Create an empty dataframe to store all results
all_results <- data.frame(Dyad = character(), stringsAsFactors = FALSE)

# Loop through each batch
for (i in seq_along(batches)) {
  batch_files <- batches[[i]]
  df_list <- list()
  
  # Read and store each file in df_list
  for (file in batch_files) {
    df <- read_delim(file, delim = "\t", col_names = FALSE)  # Adjust delimiter if necessary
    base_name <- tools::file_path_sans_ext(basename(file))
    df_list[[base_name]] <- df
  }
  
  # Run CRQA function on the batch
  batch_results <- run_crqa_for_dyads(df_list, cross_rescale_type, average_delay, average_embedding, cross_theiler_window)
  
  # Convert results list to a dataframe
  batch_results_df <- do.call(rbind, lapply(names(batch_results), function(name) {
    data.frame(Dyad = name, t(batch_results[[name]]))
  }))
  
  # Append batch results to final dataframe
  all_results <- rbind(all_results, batch_results_df)
}

print(all_results)

all_results <- all_results
```

### Results
```{r clean-results}
if ("Dyad" %in% names(all_results)) {
  clean_results <- all_results 
  clean_results$Dyad <- sub("_Participant[12]_MEA", "", clean_results$Dyad)
}

clean_results <- clean_results %>%
  mutate(Dyad = as.numeric(sub("Dyad", "", Dyad))) %>%
  arrange(Dyad)

# Print final, cleaned results
print(head(clean_results))
```

```{r write-results-csv}
clean_results <- clean_results %>%
  mutate(across(where(is.list), ~sapply(., function(x) paste(unlist(x), collapse = ", "))))  # Flatten list columns

write.csv(clean_results, file = "your_file_name_and_location.csv", row.names = FALSE)
```

### Viewing Results
```{r results-preview}
clean_results %>% head(10)
```

# Visualizing a Few Dyads
```{r randome-sample-5}
set.seed(123)  # Set seed for reproducibility
sample_indices <- sample(nrow(clean_results), 5)
sample_clean_results <- clean_results[sample_indices, ]
sample_clean_results <- sample_clean_results %>% arrange(Dyad)

print(sample_clean_results)
```

```{r plots}
sample_clean_long <- sample_clean_results

sample_clean_long <- sample_clean_long %>%
  rename(
    Determinism = DET,
    Recurrence_Rate = RR,
    Line_Length = NRLINE,
    Max_Line_Length = maxL,
    Average_Line_Length = L,
    Entropy = ENTR,
    Relative_Entropy = rENTR,
    Laminarity = LAM,
    Trapping_Time = TT
  )

sample_clean_long <- sample_clean_long %>%
  pivot_longer(cols = c(Recurrence_Rate, Determinism, Line_Length, 
                        Max_Line_Length, Average_Line_Length, Entropy, 
                        Relative_Entropy, Laminarity, Trapping_Time),
               names_to = "Metric",
               values_to = "Value") %>%
  mutate(Dyad = as.factor(Dyad), Value = as.numeric(Value))

# Plot Metrics by 5 Random Dyads
ggplot(sample_clean_long, aes(x = Dyad, y = Value, fill = Dyad)) +
  geom_col(position = "dodge") + 
  facet_wrap(~Metric, scales = "free_y") +
  theme_minimal() +
  labs(title = "Comparison of Dyads Across Metrics",
       x = "Dyad",
       y = "Value",
       fill = "Dyad") +
   scale_y_continuous(labels = scales::number_format(accuracy = 0.1)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 

```
